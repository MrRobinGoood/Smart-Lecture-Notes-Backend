you you you you Всем привет! Сегодня мы продолжаем изучать веб-скрейпинг и перейдем к разбору Python-модуля LXML и языка XPath. В одном из предыдущих уроков мы познакомились с BeautifulSoup и использовали его для скрейпинга HTML-страниц. В текущем же уроке будем работать с модулем LXML. BeautifulSoup богаче с точки зрения функциональных возможностей, но для выполнения простых задач можно использовать LXML, а сегодня наша задача научиться писать выражения XPath, которые используются для скрейпинга нужных частей информации. В первой половине урока мы займемся теоретическим разбором инструментов, а во второй части урока применим на практике полученные знания и выполним скрейпинг сайта IMDB. Я советую вам по ходу лекции повторять все, что я делаю, то есть откройте VS Code и воспроизводите тот же код, что и в лекции. Итак, сегодня на уроке мы разберем основы LXML, XPath, поработаем с XPath в рамках LXML, поговорим о том, что такое CSS-селекторы, ну и наконец выполним скрейпинг веб-сайта с помощью XPath. Основы LXML. Начнем с определения. LXML – это библиотека Python для обработки документов XML и HTML. Она предоставляет быстрый и эффективный API для парсинга, манипулирования и сериализации данных XML и HTML. Основные возможности LXML включают поддержку XPath и работу с деревом элементов. Давайте перейдем в нашу среду разработки visual studio code и продолжим работать там мы находимся в весь код и для начала нужно установить lxml установка lxml стандартная посредством pip install l xml у меня эта библиотека уже установлена, поэтому продолжаем работу дальше. Чтобы начать работу с LXML, давайте возьмем элементарную HTML-страницу и посмотрим на ее структуру. Как видно, тело страницы содержит один параграф Hello Geekbrains, один список, внутри которого находятся элементы, и второй из элементов содержит тег гиперссылки. Можно запустить этот файл прямо из среды разработки. Для этого нужно установить расширение, которое называется Live Server. Для этого перейдем на вкладку расширения. В строке поиска напишем Live Server. У меня это расширение уже установлено. После установки расширения возвращаемся на нашу страницу, жмем правую кнопку мышки и выбираем Open with Live Server. Нажимаем и наша HTML-страница откроется в браузере. Пока что мы работаем с игрушечным примером, но это нужно для учебных целей. Позже мы будем работать с настоящим сайтом. Сейчас, чтобы остановить сервер, нужно кликнуть в правом нижнем углу на вот этом значке Port. Сервер остановлен. Теперь давайте создадим новый Python файл в нашем корневом каталоге и назовем его app.py. Что мы сейчас будем делать?отеки LXML. Импортируем E3. Модуль E3 имеет функцию parse, которая принимает в качестве аргумента источник, который может быть файлом или частью файла. Так что в качестве аргумента мы указываем относительный путь к нашему HTML файлу. И давайте создадим переменную E3, в которой сохраним результат. сохраним результат. В качестве аргумента указываем путь к файлу нашему веб-пейдж, он у меня находится в директории src. И давайте выведем значение переменной, сохраним наш скрипт и запустим его в терминале функция parse как вы видите возвращает объект который называется элемент 3 что произошло функция parse берет html файл и преобразует его в дерево о дереве html мы говорили с вами во второй лекции сейчас возвращаемся к этой теме. С нашей точки зрения HTML файл это текст с определенным синтаксисом внутри. В то же время XML или HTML может быть рассмотрено как дерево элементов. Давайте посмотрим на нашем примере и выведем элементы дерева. Чтобы вывести элементы дерева, воспользуемся уже готовым скриптом. У меня он называется Parse3. Давайте его запустим. Я не буду сейчас погружаться в детали кода. Вы можете, используя конспект лекции, разобраться, поскольку сейчас это не является целью нашей лекции. Запустим скрипт. Итак, что мы получили? Мы получили древовидную структуру, в которой все теги преобразованы в объекты элемент. В этой древовидной структуре элемент HTML является корневым элементом. И у него есть два дочерних элемента head и body. Элемент head имеет один дочерний элемент title. Элемент body имеет два дочерний элемент, title. Элемент body имеет два дочерних элемента, p и ul. Элемент ul, в свою очередь, имеет два дочерних элемента, это элементы li. Первый элемент li имеет атрибут id, установленный на myid. И второй элемент li имеет атрибут class, установленный в myClass, и содержит один дочерний элемент, элемент a. В общем, в древовидной структуре HTML элемент считается родительским, если он имеет один или несколько дочерних элементов, а дочерний элемент это элемент вложенный в другой элемент. Итак, давайте представим, что мы хотим извлечь или сделать скрепинг заголовка нашей HTML страницы. Мы можем это сделать, потому что теперь у нас есть дерево элементов и существует метод, который позволяет извлечь заголовок из нашей веб-страницы. У нашего объекта Element3 есть метод find, который принимает в качестве аргумента путь к элементу или тегу, который мы хотим извлечь. В нашей HTML-разметке мы знаем, что заголовок находится внутри тега head. Поэтому в методе find мы вводим строковое значение путь к заголовку headTitle. Давайте создадим новую переменную. Назовем ее titleElement и используем метод find. В качестве аргумента укажем путь к заголовку. Укажем путь к заголовку. И на этот раз выведем значение переменной titleElement. Сохраним скрипт и запустим его еще раз. Это выражение вернет элемент title. Объект элемент типа title. Если теперь мы хотим вывести фактическое значение заголовка, то можем вызвать свойство текст элемента title. Давайте допишем в код. Точка текст. Сохраним скрипт. Очистим терминал. И запустим скрипт еще раз. Пожалуйста, мы получили текстовое значение элемента title. Thank you. И так далее. на этот вопрос давайте посмотрим еще раз код нашей веб-страницы. И здесь видно, что тег title находится внутри тега head, а тег head находится внутри тега html. Мы всегда должны начинать с одного из прямых дочерних элементов. Например, если мы хотим выбрать тег абзаца pHelloGeekBrain, мы должны начать с тега body, потому что body является прямым дочерним элементом тега HTML. Выведите текст абзаца pHelloGeekBrain, используя метод find. Сейчас поставьте видео на паузу и возвращайтесь с результатом. Итак, чтобы вывести содержимое тега p, мы воспользуемся все тем же методом 3.Find, но только изменим путь к тегу абзаца. Путь будет body и наш целевой тег p. Сохраним скрипт. Запустим его в терминале. Пожалуйста, мы получили текст тега p. В качестве альтернативы методу find у нас есть другой метод findAll. Аналогично тому, как мы изучали с beautiful soup. По его названию понятно, что он будет находить все совпадающие теги и возвращать их в виде списка. Например, чтобы выбрать все элементы списка, которые находятся внутри тега ul, давайте посмотрим в нашем html коде. Итак, мы хотим выбрать все элементы списка внутри ul, мы должны использовать метод findAll, потому что если мы используем метод find, то получим только первый элемент списка. Давайте попробуем извлечь элементы li или элементы списка. Вернемся в наш скрипт и создадим переменную listItem и используем на этот раз метод findAll. И в качестве пути укажем body, список, ul и элементы.li. И выведем наш список элементов. Список UL и элементы LI. И выведем наш список элементов. Сохраняем скрипт. Запускаем его. Мы получили список из двух элементов типа li. Чтобы извлечь текстовое содержимое, нужно обратиться к каждому элементу списка отдельно, поэтому нам придется создать цикл for и в цикле проходим по каждому элементу и выводим его. И выведем текстовое содержимое. Сохраняем скрипт, запускаем его. Обратите внимание, что для первого элемента списка мы получили полное текстовое значение. Однако для второго элемента списка мы не видим содержимого тега a. Причина здесь в том, что в методе findAll мы указали, что хотим получить все элементы списка и нас не интересует, есть ли внутри него тег a. Чтобы решить эту проблему, нужно внутри цикла создать переменную или что-то еще. Поэтому одно быстрое решение, которое мы можем применить, это осуществить поиск внутри цикла for. Давайте создадим переменную еще одну внутри цикла, назовем ее a, и внутри элемента li используем метод find для поиска тега a. Так как у нас только один элемент содержит тег a, то используем оператор if, и если a не равно non, значит внутри элемента списка есть тег a, содержимое которого мы соответственно и выведем. Если А из нот нон, иными словами, если А существует, то выведем его в текстовое содержимое. Здесь мы это должны заключить в фигурные скобки. В противном значении просто выводим текстовое содержимое элемента a. Этот принт нам больше не нужен, сохраняем. Я здесь не указал кавычки. Сохраняем и запускаем скрипт Обратите внимание, что теперь мы получили текстовое содержимое тега a со словом developer Но перед словом developer есть большой пробел Это связано с нашей HTML разметкой, где есть пробелы перед словом developer Чтобы очистить вывод, мы можем использовать метод python.strip. Добавим в код strip, сохраняем и запускаем наш скрипт еще раз. На этот раз все в порядке. Одним из недостатков LXML является то, что он не богат в плане методов, которые открываются нам через объекты Element3. Более того, каждый раз, когда мы хотим выбрать тег из разметки HTML, мы должны указать абсолютный путь до тега. Если мы имеем дело с большой HTML-страницей, это может быть проблемой. Чтобы решить эту проблему, существует более эффективный метод выбора тегов с помощью XPath. Переходим к следующей теме. Что такое XPath? XPath означает XML Path Language, язык запросов к элементам XML документа. Язык XPath используется для уникальной идентификации или адресации частей XML документа. Выражение XPath можно использовать для поиска в XML документе и извлечения информации из любой части документа. информации из любой части документа. Например, элемента или атрибута. В XML он называется узлом или node. Но это, конечно, не означает, что мы не можем использовать его для запроса и выбора элементов или тегов из HTML-страницы. Мы начнем изучение XPath с выражений. XPath expressions. xpath с выражений. xpath expressions. Выражение, определяющее шаблон для выбора узлов. Как мы уже обсуждали, HTML документ рассматривается как дерево узлов. В xpath мы можем выбрать элемент, используя двойной слэш и затем имя элемента. Например, если вы хотите выбрать все div на HTML-странице, мы используем двойной слэш div. Также мы можем выбрать элементы по их атрибуту, ID или классу, добавляя две квадратные скобки, следующие за именем элемента, а затем значение атрибута. Мы можем выбрать элемент на основе его позиции. Например, если вы хотите выбрать первый элемент списка ul, то в квадратных скобках указываем 1. Если мы хотим выбрать первый и второй элемент списка, мы должны использовать функцию position плюс логический оператор. Например, li и в квадратных скобках указываем position равно 1 или position равно 2. Чтобы выбрать только первый элемент списка, и этот первый элемент списка должен содержать текст hello, то мы используем функцию contains. В XPath все, что мы пишем в квадратных скобках, называется предикатом или условием. У XPath есть еще одно полезное свойство. Это возможность перемещаться в дереве HTML вверх или вниз, используя то, что называется оси XPath. В XPath оси – это способ выбора элементов, которые находятся относительно текущего элемента в иерархии документа. Ось это именованная связь между элементами, которая определяет направление и набор узлов для выбора. Например, ось предков ancestor выбирает все элементы предки, то есть элементы расположенные выше в иерархии документа, а ось потомков выбирает все элементы потомки, которые идут после текущего элемента. Синтаксис на слайде. Мы указываем имя оси, двойное двоеточие и затем целевой элемент, который мы ищем. Для перехода вверх по дереву HTML есть 4 оси. Первая называется parent, которая возвращает родителя указанного узла. Вторая ancestor, чтобы получить всех предков определенного узла. Третья ось Preceding выбирает все узлы, которые появляются перед текущим узлом за исключением предков, узлов, атрибутов и пространства имя. Четвертая Preceding Sibling возвращает братьев определенного элемента, то есть все элементы одного уровня до текущего узла. Для перехода вниз по дереву HTML существуют следующие оси. Ось Child, которая будет получать дочерние элементы потомков определенного узла. Ось Following вернет все элементы, находящиеся после закрывающего тега определенного узла. Ось Following Sibling возвращает все элементы одного уровня после текущего узла. И наконец ось Descendant возвращает всех потомков текущего узла. Перейдем к следующей части и посмотрим как на практике применять xpath в рамках LXML. Итак, возвращаемся в VS Code. Удалим лишние строки, которые нам сейчас не нужны. Оставим только дерево элементов. Для выбора тегов с помощью XPath в LXML мы можем заменить наш метод find, который мы ранее использовали, методом XPath. Метод XPath принимает в качестве аргумента путь к целевому тегу, точно так же, как и метод find. Но особенность его состоит в том, что нам не нужно указывать полный путь для тега. Давайте попробуем выполнить парсинг заголовка. Создадим переменную titleElement, возьмем наше дерево и на этот раз вместо метода качестве аргумента просто указываем тег title и выведем его на печать. Метод xpath возвращает список, поэтому чтобы получить доступ к свойству текст нам нужно получить доступ к первому элементу списка, поэтому выведем title элемент и используем первый элемент списка и возьмем текст. Сохраняем скрипт и запустим. Мы получили текстовое содержимое тега title. Далее xpav позволяет нам получить доступ к тексту без использования свойства текста, связанного с lxml. То есть без вот этого свойства. И получить тот же результат. Выполняется это следующим образом. тот же результат. Выполняется это следующим образом. Мы используем функцию текст прямо в xpath выражения и также получаем доступ к первому его элементу. Соответственно, вот эта часть кода нам не нужна. выводим только содержимое значения переменной titleElement. Давайте очистим терминал и запустим еще раз наш скрипт. Мы получили тот же самый результат. задание. Попробуйте самостоятельно получить доступ к тексту тгп и вывести текст Hello Geek Brains. Поставьте видео на паузу и возвращайтесь, когда сделаете задание. Возвращаемся в VS Code. Давайте теперь получим данные из списка в HTML документе с помощью XPath. Только на этот раз не будем использовать функцию текст, а воспользуемся методом toString. Создадим переменную listItems. Используем метод xPath для выбора всех элементов li. Далее в цикле for для каждого listItems выведем его значение, используя метод toString. В качестве аргумента используем li. Сохраняем скрипт и запускаем. Сохраняем скрипт и запускаем. После выполнения кода мы увидим, что получили два списка элементов, содержащих полную HTML-разметку. Чтобы получить текст, который находится внутри элементов списка, давайте создадим переменную в цикле, которая будет применять функцию XPathText к каждому элементу списка. Создадим переменную text, которая будет брать каждый элемент li, применять к нему метод xpath и И используя функцию текст, извлекать текст. И выводим значение переменной текст в каждой итерации. Очистим экран терминала и еще раз запускаем. После выполнения кода мы снова получаем два списка, однако все еще мы получаем текст со всеми специальными символами, находящимися в HTML коде. Чтобы это исправить, нужно всего лишь добавить точку перед двойным слэшем функции текст. То есть здесь мы просто ставим точку, сохраняем, запускаем скрипт еще раз. На этот раз получаем только текст двух тегов li. Пока что мы получили два списка, первый из которых содержит только один элемент с текстом, а второй содержит три элемента, но все еще содержит пробелы. Давайте избавимся от этих лишних символов. Для этого мы можем использовать метод map, который принимает в качестве первого аргумента функцию, которая будет применена к каждому элементу списка. И используем стрип, чтобы удалить все пробелы и n символы переноса строки. Дополним наш код. Используем map и применим стрип к каждому элементу. Далее преобразуем в список наш вывод, очистим терминал и запускаем скрипт еще раз. Наконец, чтобы код возвращал не списки, а только код текст, мы можем использовать другую функцию Python. Python.join. И здесь, в свою очередь, нам уже список больше не нужен. Выводим значение переменной текст, сохраняем скрипт и запускаем его в терминале. Мы получили чистый текст. Наконец, давайте посмотрим пример работы с осями XP. Выберем все элементы li, которые являются потомками элемента ul. Если я говорю немного непонятно, возвращайтесь к HTML коду и сверяйтесь с исходным HTML кодом. Итак, меняем выражение XPath, чтобы выбрать всех потомков тега UL. Для этого используется слово descendant li. Сохраняем, запускаем скрипт. Вы можете свериться с HTML и убедиться, что мы выбрали все элементы li, которые являются потомками элемента ul. Таким образом, XPath это мощный инструмент для выбора и навигации по элементам в документах XML и HTML, который особенно полезен для задач веб-скрейпинга и извлечения данных. В этой части лекции мы рассмотрели основы использования XPub в LXML для выбора и извлечения данных из HTML документов. А сейчас давайте познакомимся с еще одним инструментом для извлечения данных из HTML-кода, это CSS-селектора. Как вы знаете, CSS служит для стилизации HTML-страниц. Идея состоит в том, что для скрейпинга мы можем использовать LXML вместе с CSS-селекторами для скрейпинга тега или элемента стилизации веб-страниц. Для использования CSS-селекторов нам нужно установить модуль под названием CSS-селект. установить модуль под названием css select. Устанавливается он в терминале посредством pip css select. Здесь ничего особенного, у меня он уже установлен. Теперь в нашем коде мы можем использовать метод CSS Select, который принимает в качестве аргумента CSS Selector. Например, чтобы выбрать заголовок из HTML страницы, все, что нам Давайте в очередной раз перепишем наш скрипт. Создадим переменную titleElement и на этот раз используем метод CSSSelect. В качестве аргумента указываем title и выведем значение, которое также будет представлено в виде списка, поэтому берем только нулевой элемент или первый элемент, сохраняем скрипт и запускаем наш код. Если выполнить файл в таком виде, то мы, как вы видите, получили ошибку attributeError. Это связано с тем, что CSS Select работает непосредственно с HTML элементами, а не с объектом Element3, как это делает XPub. Поэтому предварительно нужно конвертировать Element3. Создадим для этого новую переменную, назовем ее html и воспользуемся функцией getRoot. Эта функция конвертирует объект дерева в HTML элемент. Сохраняем наш скрипт, очистим терминал и запускаем скрипт. И здесь я снова получил ошибку attributeError. У объекта нет атрибута CSS Select. с с с select это связано с тем что здесь нужно 3 поменять на html исправляем сохраняем и запускаем еще раз на этот раз все в порядке мы получили текстовое содержимое тега тайт задание. используйте метод css selector вместо xpav и выберите тег абзаца. поставьте видео на паузу и после выполнения возвращайтесь. Итак, CSS Select и XPath – это два разных языка запросов, используемых для извлечения данных из документов HTML и XML. Хотя оба языка служат схожим целям, у них есть несколько ключевых различий, которые делают их подходящими для разных случаев использования. подходящими для разных случаев использования. XPath более мощный и гибкий язык запросов, чем CSS Select, поскольку он позволяет использовать более сложные выражения и поддерживает более широкий спектр типов данных и функций. XPath также поддерживает оси, которые позволяют перемещаться по иерархии дерева и выбирать элементы на основе их связи с другими элементами. CSS Select, с другой стороны, является более простым и лаконичным языком запросов. CSS Select может быть полезен для задач веб-скрейпинга, связанных с выбором элементов на основе их класса, ID или других CSS-селекторов, и часто для таких задач его просто проще понимать и использовать чем экспо одним из основных преимуществ ссср select перед экспо является то что он может быть быстрее и эффективнее для определенных типов выбора особенно при выборе на основе атрибутов класса или айди однако важно отметить что экспо в целом является более мощным и гибким языком запросов и лучше подходит для более сложных задач извлечения данных, которые включают выбор элементов на основе их текстового содержимого, структуры и других атрибутов. В целом, выбор языка зависит от конкретных требований задачи извлечения данных. А сейчас давайте перейдем к скрейпингу веб-сайта с помощью XPath. Мы переходим к следующему разделу лекции и займемся скрейпингом сайта IMDb, а именно страницы с топ наиболее популярных фильмов. Познакомимся с некоторыми хитростями, которые помогут вам скрейпить веб-страницы, избавимся от ненужных классов, внедренных в JavaScript, а также сохраним скрипированные данные в базе данных MongoDB. Давайте напишем код, который будет извлекать из приведенной таблицы название, место в рейтинге, изменение в место в рейтинге на странице наиболее популярных фильмов. Как вы знаете, большинство сайтов используют JavaScript. И проблема состоит в том, что библиотека Requests из Python, с которой мы уже знакомы, не понимает, не видит JavaScript. Поэтому высоки шансы, что мы не получим ту же самую информацию, которую видим при отображении страницы в браузере. Поэтому, чтобы исключить JavaScript из разметки, можно использовать следующий способ. В Chrome нажимаем три вертикальных кнопки в правом верхнем углу, переходим в настройках нужно найти в поиске элемент с названием JavaScript или просто можно написать Java. Здесь находим настройки сайтов, переходим в настройки. И в настройках ищем контент и в нем раздел JavaScript. Переходим в него. И здесь мы видим переключатель, который позволяет разрешить сайтом использовать JavaScript, либо запретить сайтом использовать JavaScript. Сейчас мы запрещаем использовать JavaScript. Возвращаемся к нашей целевой странице, и ее нужно обновить. После обновления мы видим, что некоторые элементы пропали, например, ваш рейтинг. И в общем-то это тот контент, который видит библиотека requests.python. Давайте перейдем в нашу среду разработки. В среде разработки создадим новый файл. Назовем его, например, app2.py. И давайте для начала выполним запрос get к нашему целевому сайту. Для этого для начала импортируем библиотеку requests. Создадим переменную с ответом, назовем ее resp. И воспользуемся методом get, который принимает аргументы URL с значением URL адреса нашего целевого сайта. Скопируем адрес, возвращаемся в s-код, вставляем сюда адрес и давайте укажем еще один аргумент. Это будет заголовок и в фигурных скобках укажем User Agent или агент пользователя где взять агент пользователя ну одним из самых простых способов является просто загуглить его давайте вернемся в chrome и прежде чем получить наш агент пользователя, нужно разрешить сайтам использовать JavaScript. И в поиске просто пишем myuseragent. И в Chrome отображается наш агент пользователя. Копируем его отсюда, возвращаемся в scot и указываем его в аргументе header. Указание вашего агента пользователя в аргументе запроса является хорошим тоном по ряду причин. Во-первых, некоторые веб-сайты могут блокировать запросы, которые не имеют действительного агента-пользователя или имеют необычный агент-пользователя. Во-вторых, некоторые сайты могут предоставлять различное содержимое или различную HTML-разметку в зависимости от пользовательского агента, личную HTML-разметку в зависимости от пользовательского агента, запрашивающего браузера. Наконец, некоторые сайты могут иметь соглашение об использовании, которое запрещает скрейпинг или извлечение данных. Указывая действительный пользовательский агент в строке запроса, вы идентифицируете себя как законного пользователя сайта, а не скрейпера или бота, который может нарушать условия обслуживания. И давайте выведем значение ответа сервера, а точнее статус код, чтобы проверить, что мы получили ответ от сервера. ответ от сервера. Сохраняем скрипт, запустим его и здесь мы получили ошибку в связи с тем, что опечатка в аргументе headers. Добавим s, сохраняем и запускаем еще раз. Итак, мы получили ответ 200, то есть успешный ответ сервера. Давайте начнем с построения дерева. Для этого нам нужно импортировать HTML из LXML. И теперь попробуем получить переменную дерева. Назовем ее 3. Используем функцию fromString и в качестве аргумента используем свойства контент нашего get-ответа от сервера. Данная строка создает парсинг дерева l.xml из содержимого объекта ответа. Метод fromString используется для создания нового объекта Element из HTML содержимого ответа, который хранится в атрибуте Content. Сохраним. И сейчас давайте вернемся к сайту. Для начала убедимся, что JavaScript отключен. Теперь кликаем правой кнопкой мышки на странице, выбираем просмотреть код и переходим к инструменту разработчика. Давайте для начала найдем название первого фильма. Для этого выберем инструмент поиска, наводим на название первого фильма и давайте посмотрим на HTML-код. Как вы видите, тег A находится внутри тела таблицы, который в свою очередь находится внутри таблицы. Тейбл, который содержит два класса, chartFullWith и datacolorName. chart full width и data color name. Нам нужно получить доступ вот к этому тексту, к названию фильма, поэтому давайте начнем писать XPath выражение. Нажимаем Ctrl F и в появившейся строке поиска вводим XPath выражение. Двойной слэш. Сначала нам нужно получить доступ к таблице, к тегу table. Пишем table. Далее, в квадратных скобках мы указываем значение атрибутов. Если щелкнуть дважды на значение атрибута, можно его скопировать и перенести в строку поиска. Итак, мы хотим найти значение DataColorName равным. Вставляем скопированное значение, а именно ChartMovimeter. И как видите, здесь в строке поиска нам указывают, какое количество элементов с такими характеристиками было найдено в HTML коде. В нашем случае 1. 1, потому что таблица у нас одна. Далее, внутри этой таблицы ищем следующий тег, а именно tbody. Тоже найден один элемент. Как видите, мы не должны указывать весь полностью путь. Мы указываем только те дочерние элементы, которые содержат целевой наш тег с названием фильма. Следующий элемент у нас TR. TR это строка. И сейчас, как вы видите, у нас найдено 100 таких элементов. 100, потому что на этой странице указано 100 наиболее популярных фильмов, что соответствует нашему запросу. Давайте скопируем это выражение xpath и вернемся обратно в VS Code. В нашем коде давайте создадим новую переменную, назовем ее movies. И используя наше дерево элементов и метод xpath, в качестве аргумента укажем наше xpath выражение в кавычках. Сохраняем. Значит эта переменная представляет собой список, который будет содержать все элементы типа tr, из которых нам нужно получить содержимое. Давайте сейчас создадим цикл, в котором будем проходить по всему списку. Для каждого фильма в списке фильмов. Это у нас заготовка. Теперь нам нужно опять вернуться в хром. В хроме здесь у нас первый TD элем элемент, наводим на него мышкой и видим, что подсвечивается первый столбец в таблице. Второй элемент тд это второй элемент или второй столбец в таблице. Внутри второго тега td есть тег a, который, кроме прочего, и содержит текстовое значение, а именно название фильма. Давайте получим к нему доступ с помощью expa. Дописываем наше выражение. Дописываем наше выражение. Следующий тег после tr у нас td. Нам нужен элемент td, значение атрибута класса которого равно title.column. Поэтому в квадратных скобках указываем класс и его значение. В нашем случае это title-column, можно его скопировать. Мы получили 100 таких элементов, нам же нужен один. Мы получили 100 таких элементов, нам же нужен один. Поэтому внутри этого элемента находим тег A и из него можем извлечь текст. Копируем наше XPath выражение и возвращаемся в VS Code. Теперь внутри цикла добавим ключ. Мы извлекаем название фильма, поэтому назовем его name. И находим внутри каждой переменной movie с помощью xpath название фильма. Но поскольку нам не нужен уже здесь полный путь, так как мы его сейчас прописывали в хроме, его сюда конечно можем скопировать но на самом деле часть и из этого пути уже содержится в самом movie поэтому мы оставляем только ту часть которая идет после the art то есть начиная с тега Т.Д. Все предыдущее можно удалить. Ставим здесь точку перед двумя слэшами. И нам нужно получить доступ только к первому элементу списка. Сохраняем. Возвращаемся дальше в Chrome. Теперь нам нужно получить год выпуска фильма. Воспользуемся инструментом поиска. Наведем на год выпуска, щелкаем по нему. Наведем на год выпуска, щелкаем по нему. И, как видите, год выпуска содержится в теге span. Пропишем xpath до года выпуска. Итак, у нас год выпуска находится в tbody, tr. находится в т-body, но начиная с td мы должны изменить xpath выражение и обратиться к тегу span, найти тег span, как видите их много давайте еще раз посмотрим на него. Нам нужен текст-план, значение атрибута класса которого равно secondaryInfo. Поэтому в квадратных скобках пишем class равно secondaryInfo. Все, мы получили доступ к году выпуска фильма. Выделяем и копируем XPath выражение и возвращаемся обратно в код. В коде создадим новый ключ. Назовем его «releaseEA». Также обращаемся к movie с помощью метода «xpath» и прописываем «xpath» выражение, которое мы скопировали. Давайте его отредактируем аналогичным образом. То есть мы начинаем поиск, начиная с тега td. Здесь не забываем ставить точку. И обращаемся только к нулевому элементу. Да, мы не создали словарь, поэтому давайте сейчас это сделаем и все наши данные будем записывать в словарь. Назовем его просто m и все, что мы написали, завернем в фигурные скобки. Те же действия нам нужно повторить и для остальных элементов на в именно позицию в рейтинге, изменение позиции в рейтинге и также значение title метра. Сейчас я вернусь на страницу и покажу что это. Значение title метра на этой странице это вот эта стрелочка, которая указывает в какую сторону изменился рейтинг, вверх или вниз. Давайте воспользуемся инструментом поиска, наведем на него. И в коде мы видим, что здесь title.meter.up, то есть рейтинг вырос. Давайте посмотрим, что в других элементах. Здесь title-meter-down. Попробуйте извлечь и само слово down из этого элемента. Итак, ставьте видео на паузу и возвращайтесь через некоторое время. через некоторое время. Итак, надеюсь у вас все получилось. Вы можете свериться с кодом, приведенным на экране или в конспекте коллекции. Теперь давайте создадим пустой список, назовем его allmo Movies, который будет содержать все наши данные и в цикле будем записывать в этот список словари. И на этом пока все. Давайте выведем наш спист и запустим его. Запускаем. Итак, мы получили список словарей и общую длину элементов списка равную 100, что соответствует количеству фильмов на целевой странице. некоторые поля содержат специальные символы, некоторые поля могут содержать какую-то лишнюю информацию. Поэтому дальнейшая ваша задача, следующий шаг – это выполнить парсинг элементов с помощью тех методов, которые мы уже изучали на том уроке, когда проходили Beautiful Soup и на семинарах. Поэтому сейчас я не буду останавливаться подробно на том, как извлекать информацию из каждого элемента списка и приведу сразу готовый код. Итак, я вам, конечно, рекомендую самостоятельно выполнить парсинг каждого элемента для извлечения точно той информации, которая вам нужна. Здесь же, в частности, например, год выпуска преобразован в тип int, в целое число. Здесь позиция также преобразована в целое число. Также мы извлекаем только ту информацию, которая нам нужна. Наконец, следующий этап – это добавление данных в MongoDB. Давайте напишем функцию для добавления полученных данных в локальное хранилище mango db для этого импортируем манга client из пойманга И напишем функцию, назовем ее insertToDB, в которую будем передавать список фильмов. Подключаемся к локальному клиенту. Далее создаем в нашей базе данных новую базу, назовем ее TopMovies. И, наконец, воспользуемся методом insertMany для добавления нашего списка. И, наконец, закроем клиент. После цикла вызовем нашу функцию и передадим ей список, который мы получили в результате скрейпинга. Вывод в терминал удалим, он нам больше не нужен. Сохраняем скрипт. Очистим терминал. И прежде всего давайте перейдем в Mango Compass, чтобы посмотреть, что там в настоящее время базы данных нет. Вам нужно локально запустить Mango DB. Вы можете убедиться, что сейчас базы данных с названием IMDB Movies у нас нет. И, в общем-то, наша задача сейчас сюда перенести данные. Вернемся в код. Наконец, прежде чем мы запустим наш скрипт, я хотел бы обратить ваше внимание еще на две функции, которые я сюда добавил. Первая из этих функций извлекает изменение title метра, то есть повысился рейтинг фильма или повысился рейтинг фильма или понизился рейтинг фильма, или остался без изменений. И вторая функция получает изменение позиции, то есть на сколько пунктов изменился рейтинг. Итак, пробуем запускать скрипт. Ждем ответ сервера. Скрипт выполнился. И давайте перейдем в MongoDB. Мы можем обновить список баз данных, если вновь созданная база данных все еще не отображается у вас в списке. Видим, что у нас появилась АМДБ Movies, наша новая база данных. Можем развернуть ее, внутри увидеть коллекцию Top Movies. Давайте войдем в нее. Здесь мы видим, что у нас имеется 100 элементов, что соответствует количеству фильмов на целевой странице. И, конечно, все элементы, которые мы заполучили с рейтинга IMDB, представлены в базе данных. В заключение я хочу сказать, что парсинг и скрейпинг HTML с помощью LXML и XPath это мощная техника извлечения данных с веб-сайтов. Библиотека LXML предоставляет быстрый и эффективный способ парсинга HTML, а XPath позволяет гибко и точно выбирать элементы и атрибуты в подобных документах. Комбинируя эти инструменты с Python и другими библиотеками анализа данных, можно собирать и обрабатывать большие объемы данных из интернета для использования в исследованиях, анализе или других приложениях. На этом урок окончен и до встречи на следующей лекции. you