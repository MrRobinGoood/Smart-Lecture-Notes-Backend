# Smart-Lecture-Notes-Backend
Сервис для создания конспектов лекций из транскрибированного аудио для компании GeekBrains.
## Разделы
- [Демо](#демо)
- [Стек технологий](#стек-технологий)
- [Анализ задачи](#анализ-задачи)
- [Описание проекта](#описание-проекта)
- [Ссылки на материалы](#ссылки-на-материалы)
- [Инструкция для запуска](#инструкция-для-запуска)

## Демо

Для нашего решения доступен демо чат-бот [Смарт-Методологист-Бот](https://t.me/MethodologistAssistant_bot)

*(Пароль для доступа был нами передан ответственному лицу-организатору)*

## Стек технологий

Frontend-часть находится по [ссылке](https://github.com/MrRobinGoood/Smart-Lecture-Notes-Frontend)

- Backend-часть

Язык:
- Python 3.10

Модели:
- Saiga-2-Retrieval-QA
- Whisper v.3

Средство поиска релевантных фрагментов документов:
- LangChain Retrievers

Другие библиотеки:

- HuggingFace
- SentenceTransformers
- Chromadb
- FastAPI
- Aiogram
- Pandas

Операционная система:
- Linux WSL Ubuntu 22

## Анализ задачи
Перед нами была поставлена задача по созданию ИИ, который смог бы значительно снизить нагрузку на методитов компании GeekBrains, благодаря тому, что смог бы транскрибировать, суммировать лекции, а также выделять в них важные термины, запоминая их расположение в аудиофайлах по тайм кодам.
Мы проанализировали полученное задание и выявили следующие техничесие задачи, расставив по приоритетам, которые решали в процессе хакатона.

- Распознавать текст - (найти библиотеки или LLM)
  - Англоязычные названия проверки
- Выделение-тайм кодов предложений
- Выделение терминов для сбора в Глоссарий с помощью модели ?
  - Определять если ли расшифровка термина
  - Получение тайм-кода предложения для данного термина (указывать есть расшифровка или просто упоминание)
  - Сохранение термина с расшифровкой 
  - Досохранение в существующий термин новой формулировки
  - Оценивать схожесть формулировок при досохранении термина
  - Указывать в каких лекциях используются (БД)
- Поиск
  - Поиск терминов в глоссарии
  - Поиск по расшифровкам терминов с помощью LLM QA
  - Поиск слов в расшифровке аудио, с получением тайм-кода
  - Поиск значения не расшифрованных терминов LLM/Elastic search (и сохранение расшифровки в бд)
- Конспектирование
  - Пунктуация
  - Выбрасывание слов паразитов
  - Вёрстка текста (выделение кода или терминов форматированием html)
  - Сжатие (пересказ с помощью LLM)
  - Проверка предложений на логику
  - Создание оглавления
- Парсинг фотографий

- Распознавание текста

На данном этапе перед нами возникло две проблемы: распознавание англоязычных терминов в русской речи, а также предсказание пунктуации по сплошному тексту. В процессе работы мы попробовали следующие модели: VOSK, Speech-to-text. Данные модели не устроили нас качеством транскрибации из-за невозможности распознавания англоязычных терминов корректно, а также из-за отсутсвия в русских версиях библиотек встроенных функций предсказания пунктуации. В результате мы пришли к выводу, что для распознавания речи нам не достаточно обычной библиотеки, нужна модель-нейросеть. Лучшей и современнейшей на текущий момент является библиотека Whisper V.3, которой мы успешно воспользовались.

На втором этапе мы решали задачи связанные с промпт-инжинирингом больших языковых моделей. Конспектирование, создание оглавления, получение тайм-кодов, всё это мы реализовали в приложении.
## Описание проекта
Наше решение представляет собой веб-приложение, способное транскрибировать речь человека, а затем выделять из полученного текста термины, составлять конспект лекции.
Всё наше решение можно запускать исключительно на CPU(нетребовательное), а для ускорения инференса на GPU.

В качестве библиотеки распознавания речи мы используем Whisper v.3 от компании OpenAI. Данная модель является открытой и находится под лицензией Apache 2.0. Она имеет сравнительно небольшой вес(3 ГБ) и при наличии вычислительных мощностей может выдавать быстрый инференс. 

Устройство работы данной библиотеки нетривиально и приведено на схеме:
![устройство библиотеки whisper](https://github.com/MrRobinGoood/Smart-Lecture-Notes-Backend/blob/master/resources/pic/approach.png)

Данная библиотека хорошо решает проблему англоязычных терминов встречающихся в речи, а также предсказывает пунктуацию.

После этого текстовый файл передаётся в LLM модель Saiga-2, в которой благодаря написанным промптам:
- Выделяется оглавление текста
- Выделяются термины и их тайм-коды
- Выделяются определения терминов
- Составляется краткий конспект лекции (суммаризация)

При составлении конспектов нами также используется парсинг картинок, которые обогащают лекцию и добавляют информативности.

Все материалы поступают благодаря FastAPI в фронтенд нашего приложения, где у методиста есть возможность отредактировать и скачать полученные материалы.
- Процесс подгрузки mp3 файла:
![Графический интерфейс](https://github.com/MrRobinGoood/Smart-Lecture-Notes-Backend/blob/master/resources/pic/Screenshot_1.png)

- После подгрузки отображается размер подгруженного файла в Кб:

![Графический интерфейс 2](https://github.com/MrRobinGoood/Smart-Lecture-Notes-Backend/blob/master/resources/pic/Screenshot_2.png)

- После непродолжительного ожидания открывается основное окно выбора и редактирования конспекта:

![Графический интерфейс 3](https://github.com/MrRobinGoood/Smart-Lecture-Notes-Backend/blob/master/resources/pic/Screenshot_3.png)
- В правом поле можно сменить подготовленные тексты: либо отображать тайм-коды с терминами, либо подробную транскрибацию лекции.
![Графический интерфейс 4](https://github.com/MrRobinGoood/Smart-Lecture-Notes-Backend/blob/master/resources/pic/Screenshot_4.png)
- Для конспекта доступна возможность выгрузки в .doc файл:
![Графический интерфейс 5](https://github.com/MrRobinGoood/Smart-Lecture-Notes-Backend/blob/master/resources/pic/Screenshot_5.png)

Также для нашего решения доступна демо-версия [Смарт-Методологист-Бот](https://t.me/MethodologistAssistant_bot), в которой у вас есть возможность протестировать работу транскрибирования, и составления конспекта, как записью голосового сообщения, так и прикреплением mp3 файла.

## Ссылки на материалы
- Ссылка на демо-версию [чат-бот](https://t.me/MethodologistAssistant_bot) *(пароль для доступа был передан ответственному лицу-организатору)*
- Backend представлен в [данном](https://github.com/MrRobinGoood/Smart-Lecture-Notes-Backend) репозитории.
- Frontend представлен в репозитории по [ссылке](https://github.com/MrRobinGoood/Smart-Lecture-Notes-Frontend).
- Ссылка на используемую LLM модель - Saiga-2-Retrieval-QA [model-q4_K.gguf](https://huggingface.co/IlyaGusev/saiga2_13b_gguf/blob/main/model-q4_K.gguf)
- Ссылка на кэш с моделью [Whisper](https://disk.yandex.ru/d/-pW37Kf6sEySXw)
- Ссылка на библиотекку [ffmpeg](https://disk.yandex.ru/d/ReDkMtstUx2A1w) *(путь к ней нужно также прописать в path - [инструкция](https://phoenixnap.com/kb/ffmpeg-windows); все пути не должны содержать кириллицу воизбежание ошибок, после установки путей в path может возникнуть необходимость перезагрузки компьютера)*
- Ссылка на [сформированный конспект]()
- Ссылка на [submission.csv](https://github.com/MrRobinGoood/Smart-Lecture-Notes-Backend/blob/master/resources/submission/submission.csv)
- Ссылка на обработанный [тестовый датасет](https://github.com/MrRobinGoood/Smart-Lecture-Notes-Backend/tree/master/resources/fragments)


## Инструкция для запуска
Для локального запуска на машине *(необходимые ссылки прикреплены в ссылках на материалы)*

Пошаговая инструкция:
1. Вам необходимо склонировать репозиторий
2. Скачать модель Saiga-2, её нужно поместить в директорию data/cache https://huggingface.co/IlyaGusev/saiga2_13b_gguf/resolve/main/model-q4_K.gguf
3. Для запуска проекта вам потребуется python версии 3.10, а также установленный pip
4. Создайте виртуальное окружение venv и активируйте его
5. В корневой папке проекта создайте директорию data, внутри неё разместите директорию cache
6. Скачайте кэш с моделью Whisper из ссылок на материалы, и поместите его вместо своей глобальной папки .cache (по умолчанию C:\Users\User\.cache)
7. Скачайте ffmpeg из ссылок на материалы, разместите его согласно приложенной инструкции, а также пропишите пути path
8. Для запуска следующих скриптов перейдите в корневую директорию проекта
9. Запустите командную строку из корневой директории проекта
10. Выполните следующую команду ```pip install -r requirements.txt``` для загрузки всех библиотек-зависимостей
11. Командой  ```uvicorn app:app --reload``` вы можете запустить backend-сервис
12. Затем запустите frontend сервис и воспользуйтесь доступным функционалом
14. После запуска по ссылке также http://127.0.0.1:8000/docs вы можете увидеть документацию бэкенд-сервиса.
14. Для того чтобы развернуть демо-бота локально можно запустить файл telegram_bot, предварительно сменив ключ бота token.

Для остановки backend или frontend сервиса нажмите комбинацию клавиш ctrl+c или остановите выполняемый процесс

