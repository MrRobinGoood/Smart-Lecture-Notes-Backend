# Smart-Lecture-Notes-Backend
Сервис для создания конспектов лекций из транскрибированного аудио для компании GeekBrains.
## Разделы
- [Демо](#демо)
- [Стек технологий](#стек-технологий)
- [Анализ задачи](#анализ-задачи)
- [Описание проекта](#описание-проекта)
- [Ссылки на материалы](#ссылки-на-материалы)
- [Инструкция для запуска](#инструкция-для-запуска)

## Демо

Для нашего решения доступен демо чат-бот [Смарт-Методологист-Бот](https://t.me/MethodologistAssistant_bot)

*(Пароль для доступа был нами передан ответственному лицу-организатору)*

## Стек технологий

Frontend-часть находится по [ссылке](https://github.com/MrRobinGoood/Smart-Lecture-Notes-Frontend)

- Backend-часть

Язык:
- Python 3.10

Модели:
- Saiga-2-Retrieval-QA
- Whisper v.3

Средство поиска релевантных фрагментов документов:
- LangChain Retrievers

Другие библиотеки:

- HuggingFace
- SentenceTransformers
- Chromadb
- FastAPI
- Aiogram
- Pandas

Операционная система:
- Linux WSL Ubuntu 22

## Анализ задачи

## Описание проекта
Наше решение представляет собой веб-приложение, способное транскрибировать речь человека, а затем выделять из полученного текста термины, составлять конспект лекции.
Всё наше решение можно запускать исключительно на CPU(нетребовательное), а для ускорения инференса на GPU.

В качестве библиотеки распознавания речи мы используем Whisper v.3 от компании OpenAI. Данная модель является открытой и находится под лицензией Apache 2.0. Она имеет сравнительно небольшой вес(3 ГБ) и при наличии вычислительных мощностей может выдавать быстрый инференс. 

Устройство работы данной библиотеки нетривиально и приведено на схеме:
![устройство библиотеки whisper]()

Данная библиотека хорошо решает проблему англоязычных терминов встречающихся в речи, а также предсказывает пунктуацию.

После этого текстовый файл передаётся в LLM модель Saiga-2, в которой благодаря написанным промптам:
- Выделяется оглавление текста
- Выделяются термины и их тайм-коды
- Выделяются определения терминов
- Составляется краткий конспект лекции (суммаризация)

Все материалы поступают благодаря FastAPI в фронтенд нашего приложения, где у методиста есть возможность отредактировать и скачать полученные материалы.
[Графический интерфейс]()
[Графический интерфейс 2]()
[Графический интерфейс 3]()

Также для нашего решения доступна демо-версия [Смарт-Методологист-Бот](https://t.me/MethodologistAssistant_bot), в которой у вас есть возможность протестировать работу транскрибирования, и составления конспекта, как записью голосового сообщения, так и прикреплением mp3 файла.

## Ссылки на материалы
- Ссылка на демо-версию [чат-бот](https://t.me/MethodologistAssistant_bot) *(пароль для доступа был передан ответственному лицу-организатору)*
- Backend представлен в [данном](https://github.com/MrRobinGoood/Smart-Lecture-Notes-Backend) репозитории.
- Frontend представлен в репозитории по [ссылке](https://github.com/MrRobinGoood/Smart-Lecture-Notes-Frontend).
- Ссылка на используемую LLM модель - Saiga-2-Retrieval-QA [model-q4_K.gguf](https://huggingface.co/IlyaGusev/saiga2_13b_gguf/blob/main/model-q4_K.gguf)
- Ссылка на кэш с моделью [Whisper](https://disk.yandex.ru/d/-pW37Kf6sEySXw)
- Ссылка на библиотекку [ffmpeg](https://disk.yandex.ru/d/ReDkMtstUx2A1w) *(путь к ней нужно также прописать в path - [инструкция](https://phoenixnap.com/kb/ffmpeg-windows); все пути не должны содержать кириллицу воизбежание ошибок, после установки путей в path может возникнуть необходимость перезагрузки компьютера)*
- Ссылка на обработанный [тестовый датасет]()

## Инструкция для запуска


